---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: ccd-logstash
  namespace: ccd
  annotations:
    flux.weave.works/automated: "true"
spec:
  releaseName: ccd-logstash
  rollback:
    enable: true
    retry: true
    maxRetries: 0
  chart:
    repository: https://helm.elastic.co
    name: logstash
    version: 6.8.13
  initContainers:
  - name: download-postgres-jdbc
    image: hmctspublic.azurecr.io/imported/busybox
    command:
    - wget
    - "-O"
    - "/lib/postgresql.jar"
    - https://jdbc.postgresql.org/download/postgresql-42.2.2.jar
    volumeMounts:
    - name: logstash-lib
      mountPath: "/lib"
  volumes:
  - name: logstash-lib
    emptyDir: {}
  values:
    image: "hmctspublic.azurecr.io/imported/logstash"
    imageTag: "6.8.13"
    imagePullPolicy: "IfNotPresent"
    logstashJavaOpts: "-Xms4g -Xmx8g"
    resources:
      requests:
        cpu: "2000m"
        memory: "4Gi"
      limits:
        cpu: "4000m"
        memory: "8Gi"
    envFrom:
      - secretRef:
        name: logstash-secret
    extraVolumeMounts: |
      - name: logstash-lib
        mountPath: /usr/share/logstash/lib
    logstashConfig:
      logstash.yml: |
        http.host: 0.0.0.0
        xpack.monitoring.enabled: false
        # xpack.monitoring.elasticsearch.url: ["${ES_HOSTS}"]
    logstashPipeline:
      logstash.conf: |
        input {
          jdbc {
            jdbc_connection_string => "${DATA_STORE_HOST}"
            jdbc_user => "${DATA_STORE_USER}"
            jdbc_password => "${DATA_STORE_PASS}"
            jdbc_validate_connection => true
            jdbc_driver_library => "/usr/share/logstash/lib/postgresql.jar"
            jdbc_driver_class => "org.postgresql.Driver"
            jdbc_default_timezone => "UTC"
            use_column_value => false
            parameters => {
                        "divorcej" => "DIVORCE"
                        "cmcj" => "CMC"
                        "probatej" => "PROBATE"
                        "ethosj" => "EMPLOYMENT"
                        "sscsj" => "SSCS"
                      }
            statement => "UPDATE case_data SET marked_by_logstash = true WHERE marked_by_logstash = false AND jurisdiction != :divorcej AND jurisdiction != :cmcj AND jurisdiction != :probatej AND jurisdiction != :sscsj AND jurisdiction != :ethosj RETURNING id, created_date, last_modified, jurisdiction, case_type_id, state, last_state_modified_date, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification, supplementary_data::TEXT as json_supplementary_data"
            clean_run => false
            last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_ccd"
            schedule => "* * * * * *"
          }
        }
        filter{
          json{
            source => "json_data"
            target => "data"
            remove_field => ["json_data"]
          }
          json{
            source => "json_data_classification"
            target => "data_classification"
            remove_field => ["json_data_classification"]
          }
          json{
              source => "json_supplementary_data"
              target => "supplementary_data"
              remove_field => ["json_supplementary_data"]
            }
          mutate {
              add_field => { "index_id" => "%{case_type_id}_cases" }
            }
          mutate {
            lowercase => [ "index_id" ]
          }
        }
        output {
            elasticsearch {
                hosts => ["${ES_HOSTS}"]
                sniffing => false
                index => "%{[index_id]}"
                document_type => "_doc"
                document_id => "%{id}"
                timeout => 60
            }
        }
